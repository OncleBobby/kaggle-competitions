# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

# 01_raw
input_training_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/01_raw/input_training.csv
output_training_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/01_raw/output_training_gmEd6Zt.csv
input_test_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/01_raw/input_test.csv

# 02_intermediate
input_training_stock_formatted:
  type: pandas.CSVDataSet
  filepath: ./data/stock/02_intermediate/input_training_stock.csv
input_test_stock_formatted:
  type: pandas.CSVDataSet
  filepath: ./data/stock/02_intermediate/input_test_stock.csv

# 04_feature
x_train_features_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/04_feature/x_train_features_stock.csv
x_to_submit_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/04_feature/x_train_features_sx_to_submit_stocktock.csv

# 05_model_input
x_train_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/05_model_input/x_train_stock.csv
y_train_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/05_model_input/y_train_stock.csv
x_test_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/05_model_input/x_test_stock.csv
y_test_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/05_model_input/y_test_stock.csv

# 06_models
model_stock:
  type: pickle.PickleDataSet
  filepath: data/stock/06_models/model.pkl
  backend: pickle

# 07_model_output
y_prediction_stock:
  type: pandas.CSVDataSet
  filepath: ./data/stock/07_model_output/y_submit_stock.csv
model_score:
  type: pandas.CSVDataSet
  filepath: ./data/stock/07_model_output/model_score.csv
  versioned: True